{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm as notebook_tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision import datasets \n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Grayscale(), \n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters \n",
    "epochs = 31   #the nn will train 31 times over all 50.000 images and validate itself with 12.000 images x 31  times) \n",
    "learning_rate = 0.0001 #how much the weight will be updated each time \n",
    "batch_size = 64 \n",
    "classes = 43 \n",
    "img_size = 32\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<torch.utils.data.dataloader.DataLoader object at 0x7f1acdd2e070>, <torch.utils.data.dataloader.DataLoader object at 0x7f1a26f16cd0>)\n"
     ]
    }
   ],
   "source": [
    "def get_train_valid_loader(\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           num_workers=2):\n",
    "\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "\n",
    "    # load the dataset\n",
    "\n",
    "    base_dataset = datasets.ImageFolder(\n",
    "        root='/volumes1/thesis/notebooks/data/gtsrb/GTSRB/Training', transform=transforms,\n",
    "    )\n",
    "\n",
    "    # TODO\n",
    "    split_datasets = torch.utils.data.random_split(base_dataset, [0.20,0.8])\n",
    "    global val_dataset \n",
    "    val_dataset = split_datasets[0]\n",
    "    train_dataset = split_datasets[1]\n",
    "    \n",
    "\n",
    "    global num_train \n",
    "    num_train= len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    global split \n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "    #train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    #train_sampler = SubsetRandomSampler(train_idx)\n",
    "    #valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "    global train_loader \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = train_sampler\n",
    "    )\n",
    "    global valid_loader \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = valid_sampler\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "print(get_train_valid_loader(batch_size = 64, augment = True, random_seed = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [ '0:Speed limit (20km/h)',\n",
    "            '1:Speed limit (30km/h)', \n",
    "            '2:Speed limit (50km/h)', \n",
    "            '3:Speed limit (60km/h)', \n",
    "            '4:Speed limit (70km/h)', \n",
    "            '5:Speed limit (80km/h)', \n",
    "            '6:End of speed limit (80km/h)', \n",
    "            '7:Speed limit (100km/h)', \n",
    "            '8:Speed limit (120km/h)', \n",
    "            '9:No passing', \n",
    "            '10:No passing veh over 3.5 tons', \n",
    "            '11:Right-of-way at intersection', \n",
    "            '12:Priority road', \n",
    "            '13:Yield', \n",
    "            '14:Stop', \n",
    "            '15:No vehicles', \n",
    "            '16:Veh > 3.5 tons prohibited', \n",
    "            '17:No entry', \n",
    "            '18:General caution', \n",
    "            '19:Dangerous curve left', \n",
    "            '20:Dangerous curve right', \n",
    "            '21:Double curve', \n",
    "            '22:Bumpy road', \n",
    "            '23:Slippery road', \n",
    "            '24:Road narrows on the right', \n",
    "            '25:Road work', \n",
    "            '26:Traffic signals', \n",
    "            '27:Pedestrians', \n",
    "            '28:Children crossing', \n",
    "            '29:Bicycles crossing', \n",
    "            '30:Beware of ice/snow',\n",
    "            '31:Wild animals crossing', \n",
    "            '32:End speed + passing limits', \n",
    "            '33:Turn right ahead', \n",
    "            '34:Turn left ahead', \n",
    "            '35:Ahead only', \n",
    "            '36:Go straight or right', \n",
    "            '37:Go straight or left', \n",
    "            '38:Keep right', \n",
    "            '39:Keep left', \n",
    "            '40:Roundabout mandatory', \n",
    "            '41:End of no passing', \n",
    "            '42:End no passing veh > 3.5 tons' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    Function for plotting training and validation losses\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    #plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        y_hat= model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function, without a learning step (backward pass)\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # Forward pass and record loss\n",
    "        y_hat= model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    \n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(2048,43)\n",
    "model.conv1 = torch.nn.Conv2d(1,64,kernel_size=5,stride=1)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(random_seed)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:56:38 --- Epoch: 0\tTrain loss: 2.6161\tValid loss: 1.4959\tTrain accuracy: 59.64\tValid accuracy: 56.38\n",
      "08:56:55 --- Epoch: 1\tTrain loss: 0.9349\tValid loss: 0.5866\tTrain accuracy: 89.25\tValid accuracy: 82.15\n",
      "08:57:11 --- Epoch: 2\tTrain loss: 0.2852\tValid loss: 0.3280\tTrain accuracy: 96.80\tValid accuracy: 90.41\n",
      "08:57:27 --- Epoch: 3\tTrain loss: 0.0781\tValid loss: 0.2393\tTrain accuracy: 98.66\tValid accuracy: 93.19\n",
      "08:57:43 --- Epoch: 4\tTrain loss: 0.0329\tValid loss: 0.2719\tTrain accuracy: 98.57\tValid accuracy: 92.64\n",
      "08:57:59 --- Epoch: 5\tTrain loss: 0.0437\tValid loss: 0.3312\tTrain accuracy: 96.69\tValid accuracy: 90.65\n",
      "08:58:15 --- Epoch: 6\tTrain loss: 0.1200\tValid loss: 0.2638\tTrain accuracy: 97.08\tValid accuracy: 92.74\n",
      "08:58:31 --- Epoch: 7\tTrain loss: 0.0800\tValid loss: 0.2556\tTrain accuracy: 97.52\tValid accuracy: 92.92\n",
      "08:58:48 --- Epoch: 8\tTrain loss: 0.0481\tValid loss: 0.2360\tTrain accuracy: 97.40\tValid accuracy: 93.69\n",
      "08:59:17 --- Epoch: 9\tTrain loss: 0.0363\tValid loss: 0.1385\tTrain accuracy: 99.02\tValid accuracy: 96.02\n",
      "08:59:48 --- Epoch: 10\tTrain loss: 0.0277\tValid loss: 0.1541\tTrain accuracy: 99.05\tValid accuracy: 95.91\n",
      "09:00:18 --- Epoch: 11\tTrain loss: 0.0453\tValid loss: 0.1904\tTrain accuracy: 98.32\tValid accuracy: 94.73\n",
      "09:00:49 --- Epoch: 12\tTrain loss: 0.0405\tValid loss: 0.1954\tTrain accuracy: 97.93\tValid accuracy: 95.10\n",
      "09:01:19 --- Epoch: 13\tTrain loss: 0.0466\tValid loss: 0.1578\tTrain accuracy: 98.78\tValid accuracy: 95.83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, optimizer, _ \u001b[39m=\u001b[39m training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device)\n",
      "Cell \u001b[0;32mIn [31], line 17\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, epochs):\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m     \u001b[39m# training\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     model, optimizer, train_loss \u001b[39m=\u001b[39m train(train_loader, model, criterion, optimizer, device)\n\u001b[1;32m     18\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m     20\u001b[0m     \u001b[39m# validation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [29], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m y_hat\u001b[39m=\u001b[39m model(X) \n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_hat, y_true) \n\u001b[0;32m---> 21\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m X\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0230,  0.5584,  0.4265, -0.5401, -0.3226, -0.4797,  0.0101,  1.4361,\n",
       "          0.0303,  0.2173, -0.7840, -0.5490,  0.2646, -0.4144, -0.7134, -0.4356,\n",
       "         -0.4188, -0.1231,  0.1726,  0.7069, -0.2437, -0.0236,  0.0436, -0.3826,\n",
       "         -0.6028, -0.0065,  0.3840, -0.8034, -1.3769, -0.2743, -0.8616, -1.3487,\n",
       "          0.7465, -0.5219,  0.0655, -0.1194, -0.3635,  1.8958,  0.3079, -0.1172,\n",
       "         -0.5677, -0.5561, -0.3458]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.unsqueeze(x, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('notebook_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e104bd40b3717451915a48eb0e1578acd631c83a179c8bd7a28647fdfca76f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
